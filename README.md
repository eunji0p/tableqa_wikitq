# tableqa_wikitq

# Environment

```
pyenv create -n tableqa python=3.10.9
pyenv activate tableqa
```

## File


```    
    tableqa_wikitq/
                â”‚
                â”œâ”€â”€ previous-robust-tableqa                  # ê¹ƒ í´ë¡ í•œ ì›ë³¸ íŒŒì¼ë“¤
                â”œâ”€â”€ robust-tableqa                           # ì‹¤í—˜ì— ë§ê²Œ ìˆ˜ì • ì˜ˆì •ëœ í´ë”
                â”œâ”€â”€ wtq_label_maps.json                      # ë°ì´í„°ì…‹ ì§ˆë¬¸ ìœ í˜• ë¶„ë¥˜ëœ json íŒŒì¼
```

## ğŸ“ robust-tableqa í´ë”


### config íŒŒì¼ ìˆ˜ì • (tapex_ITR_mix_wtq.jsonnet)

```    
    robust-tableqa/
                â”‚ 
                â”œâ”€â”€ configs
                â”œâ”€â”€â”€â”€â”€â”€ wtq
                â”œâ”€â”€â”€â”€â”€â”€â”€â”€ tapex_ITR_mix_wtq.jsonnet             

```

â˜‘ï¸ ì•„ë˜ë¶€ë¶„ ì„œë²„ì— ìˆëŠ” íŒŒì¼ ê²½ë¡œë¡œ ìˆ˜ì •ì´ í•„ìš”í•©ë‹ˆë‹¤!

* index_filesëŠ” ì•„ë§ˆ previous-robust-tableqaì˜ 'Experiments' í´ë” ì•ˆì— ìˆì„ ê°€ëŠ¥ì„±ì´ ë†’ìŠµë‹ˆë‹¤!

```

local index_files = {
  "index_paths": {
    "train": "DPR_InnerTableRetrieval_wikisql_with_in_batch_neg_sampling_mixed/test/wtq_original_sets/step_7603/test.ITRWikiTQDataset.train",
    "validation": "DPR_InnerTableRetrieval_wikisql_with_in_batch_neg_sampling_mixed/test/wtq_original_sets/step_7603/test.ITRWikiTQDataset.validation",
    "test": "DPR_InnerTableRetrieval_wikisql_with_in_batch_neg_sampling_mixed/test/wtq_original_sets/step_7603/test.ITRWikiTQDataset.test",
  },
};

// json íŒŒì¼ ì£¼ì†Œ
local label_map_path = {
  "label_map_file_path" : "/home/eunji/workspace/New_Eunji/wtq_label_maps.json",
};

```

* ìµœì¢… ì‹¤í–‰ ì½”ë“œ 

â˜‘ï¸ ë””ë°”ì´ìŠ¤ ìˆ˜(8ê°œ) í™•ì¸ì´ í•„ìš”í•©ë‹ˆë‹¤!

```
python src/main.py configs/wtq/tapex_ITR_mix_wtq.jsonnet --accelerator gpu --devices 8 --strategy ddp --num_sanity_val_steps 0 --experiment_name evaluate_ominitab_on_WTQ_15 --mode test --modules overflow_only original_sub_table_order --test_evaluation_name original_sets --opts test.batch_size=2 test.load_epoch=0 model_config.GeneratorModelVersion=neulab/omnitab-large-finetuned-wtq model_config.DecoderTokenizerModelVersion=neulab/omnitab-large-finetuned-wtq model_config.ModelClass=ITRRagReduceMixModel data_loader.additional.num_knowledge_passages=15
```

